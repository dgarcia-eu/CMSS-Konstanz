---
title: "LLMs to model human behavior"
author: "David Garcia, University of Konstanz"
date: "Computational Modelling of Social Systems"
output:
  xaringan::moon_reader:
    lib_dir: libs 
    css: [xaringan-themer.css, "libs/footer.css"]
    nature:
      beforeInit: ["libs/perc.js"]
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: "16:9"
---

```{r xaringan-themer, include=FALSE, warning=FALSE}
#This block contains the theme configuration for the CSS lab slides style
library(xaringanthemer)
library(showtext)
style_mono_accent(
  base_color = "#5c5c5c",
  text_font_size = "1.5rem",
  header_font_google = google_font("Arial"),
  text_font_google   = google_font("Arial", "300", "300i"),
  code_font_google   = google_font("Fira Mono")
)
```

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
```

layout: true

<div class="my-footer"><span>David Garcia - Computational Modelling of Social Systems</span></div> 

---

## So far

- Basics of agent-based modelling: the micro-macro gap
- Modelling segregation: Schelling's model
- Modelling cultures: Axelrod's model
- Basics of spreading: Granovetter's threshold model
- Opinion dynamics
- Modelling small worlds
- Scale-free networks

---

# Overview

## 1. Social simulacra

## 2. Behavioral research on LLMs

## 3. Representing populations with LLMs

## 4. Experiment effects with LLMs

---

<br>
<br>
<br>
# 1. Social simulacra

[Generative Agents: Interactive Simulacra of Human Behavior](https://dl.acm.org/doi/abs/10.1145/3586183.3606763)


[Social Simulacra: Creating Populated Prototypes for Social Computing Systems](https://dl.acm.org/doi/pdf/10.1145/3526113.3545616)

---
# Simulacra and simulation    

.pull-left[.center[![:scale 60%](figures/Simulacra.png)]]
![:scale 50%](figures/Matrix.png)
The Matrix (1999)

---

[Generative Agents: Interactive Simulacra of Human Behavior. JS Park et al.](https://dl.acm.org/doi/abs/10.1145/3586183.3606763)

.center[![:scale 95%](figures/Park1.png)]

---
# A generative agent design

.center[![:scale 95%](figures/Park2.png)]

---

# Social behavior examples
.center[![:scale 73%](figures/Park3.png)]

---
[Social Simulacra: Creating Populated Prototypes for Social Computing Systems. JS Park et al.](https://dl.acm.org/doi/pdf/10.1145/3526113.3545616)

.center[![:scale 88%](figures/Simreddit1.png)]

---
# Simulating subreddits with LLM agents
.center[![:scale 80%](figures/Simreddit2.png)]

---
# Experiment: SimReddit vs Crowdworkers
.center[![:scale 60%](figures/Simreddit3.png)]

---

<br>
<br>
<br>
# 2. Behavioral research on LLMs



[AI Psychometrics: Assessing the Psychological Profiles of Large Language Models Through Psychometric Inventories.](https://journals.sagepub.com/doi/full/10.1177/17456916231214460)


[Only a Little to the Left: A Theory-grounded Measure of Political Bias in Large Language Models](https://arxiv.org/abs/2503.16148)

---

[AI Psychometrics: Assessing the Psychological Profiles of Large Language Models Through Psychometric Inventories. Max Pellert et al.](https://journals.sagepub.com/doi/full/10.1177/17456916231214460)

.center[![:scale 85%](figures/AIpsy1.png)]

--- 

# Personality of Transformer Models
.center[![:scale 65%](figures/AIpsy2.png)]

---

# Moral foundations of AI and moderates
.center[![:scale 67%](figures/AIpsy3.png)]

---

[Political Compass or Spinning Arrow? Towards More Meaningful Evaluations for Values and Opinions in Large Language Models. Röttger et al.](https://arxiv.org/pdf/2402.16786)

.pull-left[![:scale 100%](figures/PCT1.png)]
.pull-right[![:scale 100%](figures/PCT2.png)]

---

[Only a Little to the Left: A Theory-grounded Measure of Political Bias in Large Language Models](https://arxiv.org/abs/2503.16148)


.pull-left[![:scale 100%](figures/Mats1.png)]
.pull-right[![:scale 100%](figures/Mats1.2.png)]

Aims:
1. Use a validated survey measurement: social and economic items from World Values Survey
2. Analyze LLM output as text: classification with a transformers model into agree/disagree/neither

---

# Testing prompt robustness

.pull-left[![:scale 100%](figures/Mats2.png)]
.pull-right[![:scale 100%](figures/Mats2.2.png)]

---

# Ideology in LLMs
.center[![:scale 87%](figures/Mats3.png)]


---
# Prompt effect examples
.center[![:scale 70%](figures/Mats4.png)]


---
<br>
<br>
<br>
# 3. Representing populations with LLMs

[Out of One, Many: Using Language Models to Simulate Human Samples](https://www.cambridge.org/core/journals/political-analysis/article/abs/out-of-one-many-using-language-models-to-simulate-human-samples/035D7C8A55B237942FB6DBAD7CAA4E49)

[Synthetic Replacements for Human Survey Data? The Perils of Large Language Models](https://www.cambridge.org/core/journals/political-analysis/article/synthetic-replacements-for-human-survey-data-the-perils-of-large-language-models/B92267DC26195C7F36E63EA04A47D2FE)


---
[Out of One, Many: Using Language Models to Simulate Human Samples. Lisa Argyle et al.](https://www.cambridge.org/core/journals/political-analysis/article/abs/out-of-one-many-using-language-models-to-simulate-human-samples/035D7C8A55B237942FB6DBAD7CAA4E49)

.center[![](figures/Argyle1.png)]

---
# Comparing generated words by partisans
.pull-left[![:scale 100%](figures/Argyle2.png)]
.pull-right[![:scale 100%](figures/Argyle2.1.png)]

---
.center[![:scale 60%](figures/Argyle3.png)]

---

# GPT-3 vs ANES

.center[![:scale 82%](figures/Argyle4.png)]

---

# GPT-3 vs ANES

.center[![:scale 92%](figures/Argyle4.2.png)]

---


[Synthetic Replacements for Human Survey Data? The Perils of Large Language Models. James Bisbee et al.](https://www.cambridge.org/core/journals/political-analysis/article/synthetic-replacements-for-human-survey-data-the-perils-of-large-language-models/B92267DC26195C7F36E63EA04A47D2FE)

.center[![:scale 54%](figures/Bisbee1.png)]

---

# Prompting for ANES thermometers

.center[![:scale 70%](figures/Bisbee2.png)]

---

# The problem of low variance

.center[![:scale 70%](figures/Bisbee3.png)]

---
# Low variance among groups

.center[![:scale 70%](figures/Bisbee4.png)]

---

# Only politics matters in the persona

.center[![:scale 70%](figures/Bisbee5.png)]

---
[Missing the Margins: A Systematic Literature Review on the Demographic Representativeness of LLMs. Indira Sen et al.](https://osf.io/vk3x6/download)


.center[![:scale 100%](figures/Sen2.png)]

---

<br>
<br>
<br>
# 4. Experiment effects with LLMs

[Using Large Language Models to Simulate Multiple Humans and Replicate Human Subject Studies](https://proceedings.mlr.press/v202/aher23a.html)

[Prediciting Results of Social Science Experiments Using Large Language Models](https://docsend.com/view/ity6yf2dansesucf)

---

[Using Large Language Models to Simulate Multiple Humans and Replicate Human Subject Studies. Aher et al.](https://proceedings.mlr.press/v202/aher23a.html)


.pull-left[![:scale 100%](figures/Aher2.png)]
.pull-right[![:scale 100%](figures/Aher3.png)]


---
# Replicating Milgram's experiment
.center[![:scale 100%](figures/Aher1.png)]

---
[Prediciting Results of Social Science Experiments Using Large Language Models. Ashokkumar et al.](https://docsend.com/view/ity6yf2dansesucf)

.center[![:scale 87%](figures/TE1.png)]

---
# Real and simulated effect sizes

.center[![:scale 92%](figures/TE2.png)]

---

# Simulating unpublished papers

.center[![:scale 92%](figures/TE3.png)]

---

# Group effects but not heterogeneity

.center[![:scale 100%](figures/TE4.png)]

---



# Two papers for next week

.pull-left[
![](figures/Tornberg.png)
[Simulating Social Media Using Large Language Models to Evaluate Alternative News Feed Algorithms. Petter Törnberg, Diliara Valeeva, Justus Uitermark, Christopher Bail.](https://arxiv.org/abs/2310.05984)]


.pull-right[![](figures/OASIS.png)
[OASIS: Open Agent Social Interaction Simulations with One Million Agents. Ziyi Yang et al.](https://arxiv.org/abs/2411.11581)
]


